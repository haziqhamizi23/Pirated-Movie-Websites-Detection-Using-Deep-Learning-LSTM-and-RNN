# -*- coding: utf-8 -*-
"""PSM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DwaAO1LKp6P9JbpCRvUNKcAXIqwtpdqU
"""

# =====================================================
# FULL PREPROCESSING PIPELINE (RAW → CLEAN → BALANCED)
# FEATURES: EXACT 1–28 (EXPERIMENT ALIGNED)
# =====================================================

# -----------------------------
# 1. INSTALL & IMPORT LIBRARIES
# -----------------------------
!pip install pandas numpy scikit-learn tldextract imbalanced-learn

import pandas as pd
import numpy as np
import re
import tldextract
from sklearn.preprocessing import MinMaxScaler
from imblearn.over_sampling import SMOTE

# -----------------------------
# 2. LOAD RAW DATASET
# -----------------------------
df_raw = pd.read_csv('/content/drive/MyDrive/PSM/psm1/Dataset/FULL_DATASET_RAW_RECONSTRUCTED.csv')

print("===== BEFORE CLEANING =====")
print("Dataset Shape:", df_raw.shape)
print("Class Distribution:\n", df_raw['class'].value_counts())

# -----------------------------
# 3. DATA CLEANING
# -----------------------------
df_clean = df_raw.drop_duplicates().dropna().reset_index(drop=True)

print("\n===== AFTER CLEANING =====")
print("Dataset Shape:", df_clean.shape)
print("Class Distribution:\n", df_clean['class'].value_counts())

# -----------------------------
# 4. FEATURE EXTRACTION (1–28)
# -----------------------------
def extract_28_features(row):
    url = row['Url']
    name = row['name']
    ext = tldextract.extract(url)
    tokens = [t for t in re.split(r'\W+', url) if t]

    return [
        len(url),                                # 1 url_length
        url.count('.'),                          # 2 num_dots
        len(ext.suffix),                         # 3 tld_length
        len(ext.domain),                         # 4 domain_length
        int(any(c.isdigit() for c in url)),      # 5 has_numbers
        len(name),                               # 6 name_length
        url.count('.'),                          # 7 count_dots
        url.count('-'),                          # 8 count_hyphens
        url.count('/'),                          # 9 count_slashes
        sum(c.isdigit() for c in url),           # 10 count_numbers
        int(url.startswith('https')),            # 11 has_https
        int(any(c.isdigit() for c in name)),     # 12 has_digits_in_name
        int('movie' in url.lower()),             # 13 contains_movie
        int('tv' in url.lower()),                # 14 contains_tv
        int('download' in url.lower()),          # 15 contains_download
        int('stream' in url.lower()),            # 16 contains_stream
        sum(k in url.lower() for k in
            ['movie','tv','download','stream','free']),  # 17 piracy_keyword_count
        int(any(k in url.lower() for k in
            ['movie','tv','download','stream','free'])), # 18 contains_piracy_keyword
        int(bool(re.match(r'\d+\.\d+\.\d+\.\d+', ext.domain))), # 19 is_ip_domain
        sum(not c.isalnum() for c in url),        # 20 count_special_chars
        sum(not c.isalnum() for c in url)/len(url), # 21 percent_special_chars
        len(tokens),                             # 22 word_count
        len(set(tokens))/len(tokens),            # 23 unique_word_ratio
        -sum((url.count(c)/len(url))*np.log2(url.count(c)/len(url))
             for c in set(url)),                 # 24 url_entropy
        -sum((ext.domain.count(c)/len(ext.domain))*np.log2(ext.domain.count(c)/len(ext.domain))
             for c in set(ext.domain)),          # 25 domain_entropy
        np.mean([len(t) for t in tokens]),       # 26 avg_token_length
        max(len(t) for t in tokens)              # 27 max_token_length
    ]

feature_names = [
    'url_length','num_dots','tld_length','domain_length','has_numbers',
    'name_length','count_dots','count_hyphens','count_slashes',
    'count_numbers','has_https','has_digits_in_name','contains_movie',
    'contains_tv','contains_download','contains_stream',
    'piracy_keyword_count','contains_piracy_keyword','is_ip_domain',
    'count_special_chars','percent_special_chars','word_count',
    'unique_word_ratio','url_entropy','domain_entropy',
    'avg_token_length','max_token_length'
]

X = df_clean.apply(extract_28_features, axis=1, result_type='expand')
X.columns = feature_names
y = df_clean['class']

# -----------------------------
# 5. NORMALIZATION
# -----------------------------
scaler = MinMaxScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=feature_names)

# -----------------------------
# 6. BEFORE BALANCING
# -----------------------------
print("\n===== BEFORE BALANCING =====")
print(y.value_counts())

# -----------------------------
# 7. BALANCING (SMOTE)
# -----------------------------
smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X_scaled, y)

print("\n===== AFTER BALANCING =====")
print(y_balanced.value_counts())


# -----------------------------
# 8. DISPLAY DATASET (ROWS 1–10)
# -----------------------------

print("\n===== CLEAN DATASET (ROWS 1–10) =====")
display(clean_dataset.iloc[0:10])

print("\n===== CLEAN & BALANCED DATASET (ROWS 1–10) =====")
display(balanced_dataset.iloc[0:10])

# -----------------------------
# 9. FEATURE SUMMARY
# -----------------------------

print("\n===== FEATURE SUMMARY (STATISTICAL OVERVIEW) =====")

# Summary statistics for features only (exclude class)
feature_summary = clean_dataset.drop(columns=['class']).describe().T

# Round values for cleaner display
feature_summary = feature_summary.round(4)

# Display as table
display(feature_summary)

# ======================================
# INSTALL LIBRARIES
# ======================================
!pip install tensorflow scikit-learn pandas numpy xgboost

# ======================================
# IMPORT LIBRARIES
# ======================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout

# ======================================
# LOAD DATASET
# ======================================
df = pd.read_csv("/content/drive/MyDrive/PSM/psm1/Dataset/Features 1-7.csv")

print("Dataset shape:", df.shape)
print(df.head())

# ===============================
# REMOVE LEAKAGE 100% SAFELY
# ===============================
leakage_keywords = [
    "keyword", "pirated", "movie", "film", "title",
    "is_pirated", "movie_keyword", "contains", "found", "match",
    "label", "target"
]
# Drop leakage columns to ensure fair learning
cols_to_drop = [c for c in df.columns if any(k in c.lower() for k in leakage_keywords)]
print("Removing leakage:", cols_to_drop)

df = df.drop(columns=cols_to_drop, errors="ignore")

# ======================================
# SPLIT FEATURES & LABEL
# ======================================
X = df.drop("class", axis=1)          # Input features
y = df["class"].astype(int)           # Target labels (0 = benign, 1 = pirated)

# ======================================
# SCALE FEATURES
# ======================================
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Save normal 2D scaled for ML models
X2 = X_scaled.copy()

# ======================================
# RESHAPE FOR RNN / LSTM INPUT
# Shape required: (samples, timesteps, features)
# ======================================

# RNN/LSTM require 3D input: (samples, timesteps, features)
X_rnn = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))

# Train / Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_rnn, y, test_size=0.2, random_state=42, shuffle=True
)

# ======================================
# MODEL 1:  RNN
# ======================================
rnn_model = Sequential([
    SimpleRNN(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),  # LSTM layer with gating
    Dropout(0.3),                                                       # Prevent overfitting
    Dense(1, activation="sigmoid")                                      # Binary output layer
])

rnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training RNN Model ================")
rnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)

# Predict
rnn_pred = (rnn_model.predict(X_test) > 0.5).astype(int)

# Evaluate
rnn_acc = accuracy_score(y_test, rnn_pred)
rnn_prec = precision_score(y_test, rnn_pred)
rnn_rec = recall_score(y_test, rnn_pred)
rnn_f1 = f1_score(y_test, rnn_pred)

# ======================================
# MODEL 2: LSTM
# ======================================
lstm_model = Sequential([
    LSTM(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

lstm_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training LSTM Model ================")
lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)

# Predict
lstm_pred = (lstm_model.predict(X_test) > 0.5).astype(int)

# Evaluate
lstm_acc = accuracy_score(y_test, lstm_pred)
lstm_prec = precision_score(y_test, lstm_pred)
lstm_rec = recall_score(y_test, lstm_pred)
lstm_f1 = f1_score(y_test, lstm_pred)

# ======================================
# PERFORMANCE COMPARISON TABLE
# ======================================
print("\n================ MODEL PERFORMANCE COMPARISON ================")
print(f"{'Model':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}")
print(f"RNN      {rnn_acc:.4f}     {rnn_prec:.4f}       {rnn_rec:.4f}     {rnn_f1:.4f}")
print(f"LSTM     {lstm_acc:.4f}     {lstm_prec:.4f}       {lstm_rec:.4f}     {lstm_f1:.4f}")


import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import Callback

# ======================================
# PER-EPOCH METRICS CALLBACK
# ======================================
class MetricsCallback(Callback):
    def __init__(self, X_val, y_val):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.acc = []
        self.prec = []
        self.rec = []
        self.f1 = []

    def on_epoch_end(self, epoch, logs=None):
        y_pred = (self.model.predict(self.X_val, verbose=0) > 0.5).astype(int)

        self.acc.append(accuracy_score(self.y_val, y_pred))
        self.prec.append(precision_score(self.y_val, y_pred))
        self.rec.append(recall_score(self.y_val, y_pred))
        self.f1.append(f1_score(self.y_val, y_pred))

# ======================================
# TRAIN MODELS
# ======================================
epochs = 5

rnn_cb = MetricsCallback(X_test, y_test)
lstm_cb = MetricsCallback(X_test, y_test)

rnn_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[rnn_cb],
    verbose=1
)

lstm_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[lstm_cb],
    verbose=1
)

# ======================================
# PLOT GRAPH (X-AXIS = EPOCH)
# ======================================
epoch_range = np.arange(1, epochs + 1)

plt.figure(figsize=(11,7))

# RNN metrics
plt.plot(epoch_range, rnn_cb.acc, marker='o', label='RNN Accuracy')
plt.plot(epoch_range, rnn_cb.prec, marker='s', label='RNN Precision')
plt.plot(epoch_range, rnn_cb.rec, marker='^', label='RNN Recall')
plt.plot(epoch_range, rnn_cb.f1, marker='d', label='RNN F1-Score')

# LSTM metrics
plt.plot(epoch_range, lstm_cb.acc, marker='o', linestyle='--', label='LSTM Accuracy')
plt.plot(epoch_range, lstm_cb.prec, marker='s', linestyle='--', label='LSTM Precision')
plt.plot(epoch_range, lstm_cb.rec, marker='^', linestyle='--', label='LSTM Recall')
plt.plot(epoch_range, lstm_cb.f1, marker='d', linestyle='--', label='LSTM F1-Score')

plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Per-Epoch Performance Metrics (RNN vs LSTM)")
plt.ylim(0, 1.05)
plt.grid(True)
plt.legend(loc="best")

plt.tight_layout()
plt.show()

# ======================================
# INSTALL LIBRARIES
# ======================================
!pip install tensorflow scikit-learn pandas numpy xgboost

# ======================================
# IMPORT LIBRARIES
# ======================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout

# ======================================
# LOAD DATASET
# ======================================
df = pd.read_csv("/content/drive/MyDrive/PSM/psm1/Dataset/Features 1-14.csv")

print("Dataset shape:", df.shape)
print(df.head())

# ===============================
# REMOVE LEAKAGE 100% SAFELY
# ===============================
leakage_keywords = [
    "keyword", "pirated", "movie", "film", "title",
    "is_pirated", "movie_keyword", "contains", "found", "match",
    "label", "target"
]

cols_to_drop = [c for c in df.columns if any(k in c.lower() for k in leakage_keywords)]
print("Removing leakage:", cols_to_drop)

df = df.drop(columns=cols_to_drop, errors="ignore")

# ======================================
# SPLIT FEATURES & LABEL
# ======================================
X = df.drop("class", axis=1)
y = df["class"].astype(int)

# ======================================
# SCALE FEATURES
# ======================================
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Save normal 2D scaled for ML models
X2 = X_scaled.copy()

# ======================================
# RESHAPE FOR RNN / LSTM INPUT
# Shape required: (samples, timesteps, features)
# ======================================
X_rnn = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))

# Train / Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_rnn, y, test_size=0.2, random_state=42, shuffle=True
)

# ======================================
# MODEL 1:  RNN
# ======================================
rnn_model = Sequential([
    SimpleRNN(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

rnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training RNN Model ================")
rnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)

# Predict
rnn_pred = (rnn_model.predict(X_test) > 0.5).astype(int)

# Evaluate
rnn_acc = accuracy_score(y_test, rnn_pred)
rnn_prec = precision_score(y_test, rnn_pred)
rnn_rec = recall_score(y_test, rnn_pred)
rnn_f1 = f1_score(y_test, rnn_pred)

# ======================================
# MODEL 2: LSTM
# ======================================
lstm_model = Sequential([
    LSTM(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

lstm_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training LSTM Model ================")
lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)

# Predict
lstm_pred = (lstm_model.predict(X_test) > 0.5).astype(int)

# Evaluate
lstm_acc = accuracy_score(y_test, lstm_pred)
lstm_prec = precision_score(y_test, lstm_pred)
lstm_rec = recall_score(y_test, lstm_pred)
lstm_f1 = f1_score(y_test, lstm_pred)

# ======================================
# PERFORMANCE COMPARISON TABLE
# ======================================
print("\n================ MODEL PERFORMANCE COMPARISON ================")
print(f"{'Model':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}")
print(f"RNN      {rnn_acc:.4f}     {rnn_prec:.4f}       {rnn_rec:.4f}     {rnn_f1:.4f}")
print(f"LSTM     {lstm_acc:.4f}     {lstm_prec:.4f}       {lstm_rec:.4f}     {lstm_f1:.4f}")


import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import Callback

# ======================================
# PER-EPOCH METRICS CALLBACK
# ======================================
class MetricsCallback(Callback):
    def __init__(self, X_val, y_val):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.acc = []
        self.prec = []
        self.rec = []
        self.f1 = []

    def on_epoch_end(self, epoch, logs=None):
        y_pred = (self.model.predict(self.X_val, verbose=0) > 0.5).astype(int)

        self.acc.append(accuracy_score(self.y_val, y_pred))
        self.prec.append(precision_score(self.y_val, y_pred))
        self.rec.append(recall_score(self.y_val, y_pred))
        self.f1.append(f1_score(self.y_val, y_pred))

# ======================================
# TRAIN MODELS
# ======================================
epochs = 5

rnn_cb = MetricsCallback(X_test, y_test)
lstm_cb = MetricsCallback(X_test, y_test)

rnn_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[rnn_cb],
    verbose=1
)

lstm_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[lstm_cb],
    verbose=1
)

# ======================================
# PLOT GRAPH (X-AXIS = EPOCH)
# ======================================
epoch_range = np.arange(1, epochs + 1)

plt.figure(figsize=(11,7))

# RNN metrics
plt.plot(epoch_range, rnn_cb.acc, marker='o', label='RNN Accuracy')
plt.plot(epoch_range, rnn_cb.prec, marker='s', label='RNN Precision')
plt.plot(epoch_range, rnn_cb.rec, marker='^', label='RNN Recall')
plt.plot(epoch_range, rnn_cb.f1, marker='d', label='RNN F1-Score')

# LSTM metrics
plt.plot(epoch_range, lstm_cb.acc, marker='o', linestyle='--', label='LSTM Accuracy')
plt.plot(epoch_range, lstm_cb.prec, marker='s', linestyle='--', label='LSTM Precision')
plt.plot(epoch_range, lstm_cb.rec, marker='^', linestyle='--', label='LSTM Recall')
plt.plot(epoch_range, lstm_cb.f1, marker='d', linestyle='--', label='LSTM F1-Score')

plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Per-Epoch Performance Metrics (RNN vs LSTM)")
plt.ylim(0, 1.05)
plt.grid(True)
plt.legend(loc="best")

plt.tight_layout()
plt.show()

# ======================================
# INSTALL LIBRARIES
# ======================================
!pip install tensorflow scikit-learn pandas numpy xgboost

# ======================================
# IMPORT LIBRARIES
# ======================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout

# ======================================
# LOAD DATASET
# ======================================
df = pd.read_csv("/content/drive/MyDrive/PSM/psm1/Dataset/Features 1-28.csv")

print("Dataset shape:", df.shape)
print(df.head())

# ===============================
# REMOVE LEAKAGE 100% SAFELY
# ===============================
leakage_keywords = [
    "keyword", "pirated", "movie", "film", "title",
    "is_pirated", "movie_keyword", "contains", "found", "match",
    "label", "target"
]

cols_to_drop = [c for c in df.columns if any(k in c.lower() for k in leakage_keywords)]
print("Removing leakage:", cols_to_drop)

df = df.drop(columns=cols_to_drop, errors="ignore")

# ======================================
# SPLIT FEATURES & LABEL
# ======================================
X = df.drop("class", axis=1)
y = df["class"].astype(int)

# ======================================
# SCALE FEATURES
# ======================================
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Save normal 2D scaled for ML models
X2 = X_scaled.copy()

# ======================================
# RESHAPE FOR RNN / LSTM INPUT
# Shape required: (samples, timesteps, features)
# ======================================
X_rnn = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))

# Train / Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_rnn, y, test_size=0.2, random_state=42, shuffle=True
)

# ======================================
# MODEL 1: RNN
# ======================================
rnn_model = Sequential([
    SimpleRNN(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

rnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training RNN Model ================")
rnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)

# Predict
rnn_pred = (rnn_model.predict(X_test) > 0.5).astype(int)

# Evaluate
rnn_acc = accuracy_score(y_test, rnn_pred)
rnn_prec = precision_score(y_test, rnn_pred)
rnn_rec = recall_score(y_test, rnn_pred)
rnn_f1 = f1_score(y_test, rnn_pred)

# ======================================
# MODEL 2: LSTM
# ======================================
lstm_model = Sequential([
    LSTM(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

lstm_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training LSTM Model ================")
lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)

# Predict
lstm_pred = (lstm_model.predict(X_test) > 0.5).astype(int)

# Evaluate
lstm_acc = accuracy_score(y_test, lstm_pred)
lstm_prec = precision_score(y_test, lstm_pred)
lstm_rec = recall_score(y_test, lstm_pred)
lstm_f1 = f1_score(y_test, lstm_pred)

# ======================================
# PERFORMANCE COMPARISON TABLE
# ======================================
print("\n================ MODEL PERFORMANCE COMPARISON ================")
print(f"{'Model':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}")
print(f"RNN      {rnn_acc:.4f}     {rnn_prec:.4f}       {rnn_rec:.4f}     {rnn_f1:.4f}")
print(f"LSTM     {lstm_acc:.4f}     {lstm_prec:.4f}       {lstm_rec:.4f}     {lstm_f1:.4f}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import Callback

# ======================================
# PER-EPOCH METRICS CALLBACK
# ======================================
class MetricsCallback(Callback):
    def __init__(self, X_val, y_val):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.acc = []
        self.prec = []
        self.rec = []
        self.f1 = []

    def on_epoch_end(self, epoch, logs=None):
        y_pred = (self.model.predict(self.X_val, verbose=0) > 0.5).astype(int)

        self.acc.append(accuracy_score(self.y_val, y_pred))
        self.prec.append(precision_score(self.y_val, y_pred))
        self.rec.append(recall_score(self.y_val, y_pred))
        self.f1.append(f1_score(self.y_val, y_pred))

# ======================================
# TRAIN MODELS
# ======================================
epochs = 5

rnn_cb = MetricsCallback(X_test, y_test)
lstm_cb = MetricsCallback(X_test, y_test)

rnn_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[rnn_cb],
    verbose=1
)

lstm_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[lstm_cb],
    verbose=1
)

# ======================================
# PLOT GRAPH (X-AXIS = EPOCH)
# ======================================
epoch_range = np.arange(1, epochs + 1)

plt.figure(figsize=(11,7))

# RNN metrics
plt.plot(epoch_range, rnn_cb.acc, marker='o', label='RNN Accuracy')
plt.plot(epoch_range, rnn_cb.prec, marker='s', label='RNN Precision')
plt.plot(epoch_range, rnn_cb.rec, marker='^', label='RNN Recall')
plt.plot(epoch_range, rnn_cb.f1, marker='d', label='RNN F1-Score')

# LSTM metrics
plt.plot(epoch_range, lstm_cb.acc, marker='o', linestyle='--', label='LSTM Accuracy')
plt.plot(epoch_range, lstm_cb.prec, marker='s', linestyle='--', label='LSTM Precision')
plt.plot(epoch_range, lstm_cb.rec, marker='^', linestyle='--', label='LSTM Recall')
plt.plot(epoch_range, lstm_cb.f1, marker='d', linestyle='--', label='LSTM F1-Score')

plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Per-Epoch Performance Metrics (RNN vs LSTM)")
plt.ylim(0, 1.05)
plt.grid(True)
plt.legend(loc="best")

plt.tight_layout()
plt.show()

# ======================================
# INSTALL LIBRARIES
# ======================================
!pip install tensorflow scikit-learn pandas numpy xgboost

# ======================================
# IMPORT LIBRARIES
# ======================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout

# ======================================
# LOAD DATASET
# ======================================
df = pd.read_csv("/content/drive/MyDrive/PSM/psm1/Dataset/Features 1-28.csv")

print("Dataset shape:", df.shape)
print(df.head())

# ===============================
# REMOVE LEAKAGE 100% SAFELY
# ===============================
leakage_keywords = [
    "keyword", "pirated", "movie", "film", "title",
    "is_pirated", "movie_keyword", "contains", "found", "match",
    "label", "target"
]

cols_to_drop = [c for c in df.columns if any(k in c.lower() for k in leakage_keywords)]
print("Removing leakage:", cols_to_drop)

df = df.drop(columns=cols_to_drop, errors="ignore")

# ======================================
# SPLIT FEATURES & LABEL
# ======================================
X = df.drop("class", axis=1)
y = df["class"].astype(int)

# ======================================
# SCALE FEATURES
# ======================================
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Save normal 2D scaled for ML models
X2 = X_scaled.copy()

# ======================================
# RESHAPE FOR RNN / LSTM INPUT
# Shape required: (samples, timesteps, features)
# ======================================
X_rnn = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))

# Train / Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_rnn, y, test_size=0.2, random_state=42, shuffle=True
)

# ======================================
# MODEL 1:  RNN
# ======================================
rnn_model = Sequential([
    SimpleRNN(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

rnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training RNN Model ================")
rnn_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Predict
rnn_pred = (rnn_model.predict(X_test) > 0.5).astype(int)

# Evaluate
rnn_acc = accuracy_score(y_test, rnn_pred)
rnn_prec = precision_score(y_test, rnn_pred)
rnn_rec = recall_score(y_test, rnn_pred)
rnn_f1 = f1_score(y_test, rnn_pred)

# ======================================
# MODEL 2: LSTM
# ======================================
lstm_model = Sequential([
    LSTM(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

lstm_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training LSTM Model ================")
lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Predict
lstm_pred = (lstm_model.predict(X_test) > 0.5).astype(int)

# Evaluate
lstm_acc = accuracy_score(y_test, lstm_pred)
lstm_prec = precision_score(y_test, lstm_pred)
lstm_rec = recall_score(y_test, lstm_pred)
lstm_f1 = f1_score(y_test, lstm_pred)

# ======================================
# PERFORMANCE COMPARISON TABLE
# ======================================
print("\n================ MODEL PERFORMANCE COMPARISON ================")
print(f"{'Model':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}")
print(f"RNN      {rnn_acc:.4f}     {rnn_prec:.4f}       {rnn_rec:.4f}     {rnn_f1:.4f}")
print(f"LSTM     {lstm_acc:.4f}     {lstm_prec:.4f}       {lstm_rec:.4f}     {lstm_f1:.4f}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import Callback

# ======================================
# PER-EPOCH METRICS CALLBACK
# ======================================
class MetricsCallback(Callback):
    def __init__(self, X_val, y_val):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.acc = []
        self.prec = []
        self.rec = []
        self.f1 = []

    def on_epoch_end(self, epoch, logs=None):
        y_pred = (self.model.predict(self.X_val, verbose=0) > 0.5).astype(int)

        self.acc.append(accuracy_score(self.y_val, y_pred))
        self.prec.append(precision_score(self.y_val, y_pred))
        self.rec.append(recall_score(self.y_val, y_pred))
        self.f1.append(f1_score(self.y_val, y_pred))


# ======================================
# PLOT GRAPH (X-AXIS = EPOCH)
# ======================================
epoch_range = np.arange(1, epochs + 1)

plt.figure(figsize=(11,7))

# RNN metrics
plt.plot(epoch_range, rnn_cb.acc, marker='o', label='RNN Accuracy')
plt.plot(epoch_range, rnn_cb.prec, marker='s', label='RNN Precision')
plt.plot(epoch_range, rnn_cb.rec, marker='^', label='RNN Recall')
plt.plot(epoch_range, rnn_cb.f1, marker='d', label='RNN F1-Score')

# LSTM metrics
plt.plot(epoch_range, lstm_cb.acc, marker='o', linestyle='--', label='LSTM Accuracy')
plt.plot(epoch_range, lstm_cb.prec, marker='s', linestyle='--', label='LSTM Precision')
plt.plot(epoch_range, lstm_cb.rec, marker='^', linestyle='--', label='LSTM Recall')
plt.plot(epoch_range, lstm_cb.f1, marker='d', linestyle='--', label='LSTM F1-Score')

plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Per-Epoch Performance Metrics (RNN vs LSTM)")
plt.ylim(0, 1.05)
plt.grid(True)
plt.legend(loc="best")

plt.tight_layout()
plt.show()

# ======================================
# INSTALL LIBRARIES
# ======================================
!pip install tensorflow scikit-learn pandas numpy xgboost

# ======================================
# IMPORT LIBRARIES
# ======================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout

# ======================================
# LOAD DATASET
# ======================================
df = pd.read_csv("/content/drive/MyDrive/PSM/psm1/Dataset/Features 1-7.csv")

print("Dataset shape:", df.shape)
print(df.head())

# ===============================
# REMOVE LEAKAGE 100% SAFELY
# ===============================
leakage_keywords = [
    "keyword", "pirated", "movie", "film", "title",
    "is_pirated", "movie_keyword", "contains", "found", "match",
    "label", "target"
]

cols_to_drop = [c for c in df.columns if any(k in c.lower() for k in leakage_keywords)]
print("Removing leakage:", cols_to_drop)

df = df.drop(columns=cols_to_drop, errors="ignore")

# ======================================
# SPLIT FEATURES & LABEL
# ======================================
X = df.drop("class", axis=1)
y = df["class"].astype(int)

# ======================================
# SCALE FEATURES
# ======================================
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Save normal 2D scaled for ML models
X2 = X_scaled.copy()

# ======================================
# RESHAPE FOR RNN / LSTM INPUT
# Shape required: (samples, timesteps, features)
# ======================================
X_rnn = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))

# Train / Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_rnn, y, test_size=0.2, random_state=42, shuffle=True
)

# ======================================
# MODEL 1: RNN
# ======================================
rnn_model = Sequential([
    SimpleRNN(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

rnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training RNN Model ================")
rnn_model.fit(X_train, y_train, epochs=25, batch_size=32, verbose=1)

# Predict
rnn_pred = (rnn_model.predict(X_test) > 0.5).astype(int)

# Evaluate
rnn_acc = accuracy_score(y_test, rnn_pred)
rnn_prec = precision_score(y_test, rnn_pred)
rnn_rec = recall_score(y_test, rnn_pred)
rnn_f1 = f1_score(y_test, rnn_pred)

# ======================================
# MODEL 2: LSTM
# ======================================
lstm_model = Sequential([
    LSTM(64, activation="tanh", input_shape=(1, X_rnn.shape[2])),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

lstm_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

print("\n================ Training LSTM Model ================")
lstm_model.fit(X_train, y_train, epochs=25, batch_size=32, verbose=1)

# Predict
lstm_pred = (lstm_model.predict(X_test) > 0.5).astype(int)

# Evaluate
lstm_acc = accuracy_score(y_test, lstm_pred)
lstm_prec = precision_score(y_test, lstm_pred)
lstm_rec = recall_score(y_test, lstm_pred)
lstm_f1 = f1_score(y_test, lstm_pred)

# ======================================
# PERFORMANCE COMPARISON TABLE
# ======================================
print("\n================ MODEL PERFORMANCE COMPARISON ================")
print(f"{'Model':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}")
print(f"RNN      {rnn_acc:.4f}     {rnn_prec:.4f}       {rnn_rec:.4f}     {rnn_f1:.4f}")
print(f"LSTM     {lstm_acc:.4f}     {lstm_prec:.4f}       {lstm_rec:.4f}     {lstm_f1:.4f}")


import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import Callback

# ======================================
# PER-EPOCH METRICS CALLBACK
# ======================================
class MetricsCallback(Callback):
    def __init__(self, X_val, y_val):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.acc = []
        self.prec = []
        self.rec = []
        self.f1 = []

    def on_epoch_end(self, epoch, logs=None):
        y_pred = (self.model.predict(self.X_val, verbose=0) > 0.5).astype(int)

        self.acc.append(accuracy_score(self.y_val, y_pred))
        self.prec.append(precision_score(self.y_val, y_pred))
        self.rec.append(recall_score(self.y_val, y_pred))
        self.f1.append(f1_score(self.y_val, y_pred))

# ======================================
# TRAIN MODELS
# ======================================
epochs = 25

rnn_cb = MetricsCallback(X_test, y_test)
lstm_cb = MetricsCallback(X_test, y_test)

rnn_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[rnn_cb],
    verbose=1
)

lstm_model.fit(
    X_train, y_train,
    epochs=epochs,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[lstm_cb],
    verbose=1
)

# ======================================
# PLOT GRAPH (X-AXIS = EPOCH)
# ======================================
epoch_range = np.arange(1, epochs + 1)

plt.figure(figsize=(11,7))

# RNN metrics
plt.plot(epoch_range, rnn_cb.acc, marker='o', label='RNN Accuracy')
plt.plot(epoch_range, rnn_cb.prec, marker='s', label='RNN Precision')
plt.plot(epoch_range, rnn_cb.rec, marker='^', label='RNN Recall')
plt.plot(epoch_range, rnn_cb.f1, marker='d', label='RNN F1-Score')

# LSTM metrics
plt.plot(epoch_range, lstm_cb.acc, marker='o', linestyle='--', label='LSTM Accuracy')
plt.plot(epoch_range, lstm_cb.prec, marker='s', linestyle='--', label='LSTM Precision')
plt.plot(epoch_range, lstm_cb.rec, marker='^', linestyle='--', label='LSTM Recall')
plt.plot(epoch_range, lstm_cb.f1, marker='d', linestyle='--', label='LSTM F1-Score')

plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Per-Epoch Performance Metrics (RNN vs LSTM)")
plt.ylim(0, 1.05)
plt.grid(True)
plt.legend(loc="best")

plt.tight_layout()
plt.show()